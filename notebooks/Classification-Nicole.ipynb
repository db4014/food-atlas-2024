{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Names of sheets in excel data file\n",
    "sheets = ['ACCESS','STORES','RESTAURANTS','ASSISTANCE','INSECURITY','TAXES','LOCAL','HEALTH','SOCIOECONOMIC']\n",
    "\n",
    "#Number of sheets as a range\n",
    "num_sheets=range(len(sheets))\n",
    "\n",
    "#Store each sheet as a dataframe in a dictionary\n",
    "#The key is the name of the sheet in lower case. The value is the contents of the sheet stored as a dataframe\n",
    "fea_dict={}\n",
    "keys = [sheets[i].lower() for i in num_sheets]\n",
    "for i in num_sheets:\n",
    "    fea_dict[keys[i]]=pd.read_excel('data/FoodEnvironmentAtlas.xlsx',sheet_name=sheets[i],converters={'FIPS': str}) \n",
    "\n",
    "#conveert FIPS to string so that leading zero remains\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join dataframes into one using an inner join. Join on the columns: FIPS, State, County\n",
    "fea = fea_dict[keys[0]]\n",
    "i=1 #initialize counter\n",
    "while i<len(num_sheets):\n",
    "    fea = pd.merge(fea, fea_dict[keys[i]], on=['FIPS','State','County'], how='inner')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the single joined dataframe\n",
    "fea_data=fea.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns that are percentages because they are already normalized with respecct to county population. \n",
    "# This will also prevent redundant informaiton. Colunms that were from date after target variable year were\n",
    "# not included, with the exception of poverty rates as there was no similar variable\n",
    "columns=['FIPS',\n",
    "'PCT_LACCESS_POP10',\n",
    "'PCT_LACCESS_LOWI10',\n",
    "'PCT_LACCESS_HHNV10',\n",
    "'PCT_LACCESS_SNAP15',\n",
    "'PCT_LACCESS_CHILD10',\n",
    "'PCT_LACCESS_SENIORS10',\n",
    "'GROCPTH11',\n",
    "'SUPERCPTH11',\n",
    "'CONVSPTH11',\n",
    "'SPECSPTH11',\n",
    "'SNAPSPTH12',\n",
    "'WICSPTH11',\n",
    "'FFRPTH11',\n",
    "'FSRPTH11',\n",
    "'PC_FFRSALES07',\n",
    "'PC_FFRSALES12',\n",
    "'PC_FSRSALES07',\n",
    "'PC_FSRSALES12',\n",
    "'REDEMP_SNAPS12',\n",
    "'PCT_SNAP12',\n",
    "'PC_SNAPBEN12',\n",
    "'SNAP_PART_RATE11',\n",
    "'PCT_NSLP12',\n",
    "'PCT_FREE_LUNCH10',\n",
    "'PCT_REDUCED_LUNCH10',\n",
    "'PCT_SBP12',\n",
    "'PCT_SFSP12',\n",
    "'PC_WIC_REDEMP11',\n",
    "'REDEMP_WICS11',\n",
    "'PCT_WIC12',\n",
    "'PCT_CACFP12',\n",
    "'FOODINSEC_12_14',\n",
    "'VLFOODSEC_12_14',\n",
    "'PCT_LOCLFARM07',\n",
    "'PCT_LOCLFARM12',\n",
    "'PCT_LOCLSALE07',\n",
    "'PCT_LOCLSALE12',\n",
    "'PC_DIRSALES07',\n",
    "'PC_DIRSALES12',\n",
    "'PCH_PC_DIRSALES_07_12',\n",
    "'FMRKTPTH13',\n",
    "'VEG_ACRESPTH07',\n",
    "'VEG_ACRESPTH12',\n",
    "'PCH_VEG_ACRESPTH_07_12',\n",
    "'FRESHVEG_ACRESPTH07',\n",
    "'FRESHVEG_ACRESPTH12',\n",
    "'PCH_FRESHVEG_ACRESPTH_07_12',\n",
    "'ORCHARD_ACRESPTH07',\n",
    "'ORCHARD_ACRESPTH12',\n",
    "'PCH_ORCHARD_ACRESPTH_07_12',\n",
    "'BERRY_ACRESPTH07',\n",
    "'BERRY_ACRESPTH12',\n",
    "'PCH_BERRY_ACRESPTH_07_12',\n",
    "'GHVEG_SQFTPTH07',\n",
    "'GHVEG_SQFTPTH12',\n",
    "'PCH_GHVEG_SQFTPTH_07_12',\n",
    "'RECFACPTH11',\n",
    "'PCT_NHWHITE10',\n",
    "'PCT_NHBLACK10',\n",
    "'PCT_HISP10',\n",
    "'PCT_NHASIAN10',\n",
    "'PCT_NHNA10',\n",
    "'PCT_NHPI10',\n",
    "'PCT_65OLDER10',\n",
    "'PCT_18YOUNGER10',\n",
    "'MEDHHINC15',\n",
    "'POVRATE15',\n",
    "'CHILDPOVRATE15',\n",
    "'PCT_DIABETES_ADULTS13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset dataframe\n",
    "fea_data_sub=fea_data[columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       13.0\n",
       "1       10.4\n",
       "2       18.4\n",
       "3       14.8\n",
       "4       14.1\n",
       "        ... \n",
       "3138     8.1\n",
       "3139     4.8\n",
       "3140     9.0\n",
       "3141    12.0\n",
       "3142    10.0\n",
       "Name: PCT_DIABETES_ADULTS13, Length: 3143, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_data_sub.PCT_DIABETES_ADULTS13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3143, 70)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_data_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose numerical columns\n",
    "fea_data_sub_numeric=fea_data_sub.select_dtypes([np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create correlation matrix\n",
    "corrmatrix=fea_data_sub_numeric.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCT_LACCESS_POP10</th>\n",
       "      <th>PCT_LACCESS_LOWI10</th>\n",
       "      <th>PCT_LACCESS_HHNV10</th>\n",
       "      <th>PCT_LACCESS_SNAP15</th>\n",
       "      <th>PCT_LACCESS_CHILD10</th>\n",
       "      <th>PCT_LACCESS_SENIORS10</th>\n",
       "      <th>GROCPTH11</th>\n",
       "      <th>SUPERCPTH11</th>\n",
       "      <th>CONVSPTH11</th>\n",
       "      <th>SPECSPTH11</th>\n",
       "      <th>...</th>\n",
       "      <th>PCT_HISP10</th>\n",
       "      <th>PCT_NHASIAN10</th>\n",
       "      <th>PCT_NHNA10</th>\n",
       "      <th>PCT_NHPI10</th>\n",
       "      <th>PCT_65OLDER10</th>\n",
       "      <th>PCT_18YOUNGER10</th>\n",
       "      <th>MEDHHINC15</th>\n",
       "      <th>POVRATE15</th>\n",
       "      <th>CHILDPOVRATE15</th>\n",
       "      <th>PCT_DIABETES_ADULTS13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCT_LACCESS_POP10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901991</td>\n",
       "      <td>0.120353</td>\n",
       "      <td>0.469834</td>\n",
       "      <td>0.960294</td>\n",
       "      <td>0.919663</td>\n",
       "      <td>0.336424</td>\n",
       "      <td>-0.114098</td>\n",
       "      <td>0.141654</td>\n",
       "      <td>-0.045043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080380</td>\n",
       "      <td>-0.029079</td>\n",
       "      <td>0.157304</td>\n",
       "      <td>-0.010990</td>\n",
       "      <td>0.170400</td>\n",
       "      <td>0.024031</td>\n",
       "      <td>0.083173</td>\n",
       "      <td>-0.111678</td>\n",
       "      <td>-0.115664</td>\n",
       "      <td>-0.184580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCT_LACCESS_LOWI10</th>\n",
       "      <td>0.901991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.278653</td>\n",
       "      <td>0.625093</td>\n",
       "      <td>0.890419</td>\n",
       "      <td>0.826792</td>\n",
       "      <td>0.312603</td>\n",
       "      <td>-0.099019</td>\n",
       "      <td>0.205566</td>\n",
       "      <td>-0.100324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125123</td>\n",
       "      <td>-0.104286</td>\n",
       "      <td>0.263290</td>\n",
       "      <td>-0.018282</td>\n",
       "      <td>0.170309</td>\n",
       "      <td>0.071601</td>\n",
       "      <td>-0.175580</td>\n",
       "      <td>0.149489</td>\n",
       "      <td>0.142085</td>\n",
       "      <td>-0.032667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCT_LACCESS_HHNV10</th>\n",
       "      <td>0.120353</td>\n",
       "      <td>0.278653</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.469096</td>\n",
       "      <td>0.162711</td>\n",
       "      <td>0.043476</td>\n",
       "      <td>0.112428</td>\n",
       "      <td>-0.072707</td>\n",
       "      <td>0.083795</td>\n",
       "      <td>-0.123568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118316</td>\n",
       "      <td>-0.119366</td>\n",
       "      <td>0.459477</td>\n",
       "      <td>-0.026078</td>\n",
       "      <td>-0.054357</td>\n",
       "      <td>0.083322</td>\n",
       "      <td>-0.348824</td>\n",
       "      <td>0.430246</td>\n",
       "      <td>0.431192</td>\n",
       "      <td>0.268348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCT_LACCESS_SNAP15</th>\n",
       "      <td>0.469834</td>\n",
       "      <td>0.625093</td>\n",
       "      <td>0.469096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514461</td>\n",
       "      <td>0.350932</td>\n",
       "      <td>0.127557</td>\n",
       "      <td>-0.005639</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>-0.107596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136538</td>\n",
       "      <td>-0.085277</td>\n",
       "      <td>0.468196</td>\n",
       "      <td>-0.010444</td>\n",
       "      <td>-0.035277</td>\n",
       "      <td>0.183683</td>\n",
       "      <td>-0.287963</td>\n",
       "      <td>0.373430</td>\n",
       "      <td>0.368432</td>\n",
       "      <td>0.136373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCT_LACCESS_CHILD10</th>\n",
       "      <td>0.960294</td>\n",
       "      <td>0.890419</td>\n",
       "      <td>0.162711</td>\n",
       "      <td>0.514461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823572</td>\n",
       "      <td>0.291381</td>\n",
       "      <td>-0.093925</td>\n",
       "      <td>0.107640</td>\n",
       "      <td>-0.056868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120058</td>\n",
       "      <td>-0.018676</td>\n",
       "      <td>0.243110</td>\n",
       "      <td>-0.008160</td>\n",
       "      <td>0.046794</td>\n",
       "      <td>0.215924</td>\n",
       "      <td>0.110346</td>\n",
       "      <td>-0.099466</td>\n",
       "      <td>-0.111107</td>\n",
       "      <td>-0.196180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCT_18YOUNGER10</th>\n",
       "      <td>0.024031</td>\n",
       "      <td>0.071601</td>\n",
       "      <td>0.083322</td>\n",
       "      <td>0.183683</td>\n",
       "      <td>0.215924</td>\n",
       "      <td>-0.142778</td>\n",
       "      <td>-0.110478</td>\n",
       "      <td>0.050706</td>\n",
       "      <td>-0.089650</td>\n",
       "      <td>-0.092104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308860</td>\n",
       "      <td>-0.012262</td>\n",
       "      <td>0.291096</td>\n",
       "      <td>-0.104604</td>\n",
       "      <td>-0.528833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145593</td>\n",
       "      <td>-0.008683</td>\n",
       "      <td>-0.009211</td>\n",
       "      <td>-0.057354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDHHINC15</th>\n",
       "      <td>0.083173</td>\n",
       "      <td>-0.175580</td>\n",
       "      <td>-0.348824</td>\n",
       "      <td>-0.287963</td>\n",
       "      <td>0.110346</td>\n",
       "      <td>-0.008592</td>\n",
       "      <td>-0.050280</td>\n",
       "      <td>-0.049254</td>\n",
       "      <td>-0.294468</td>\n",
       "      <td>0.190558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036969</td>\n",
       "      <td>0.431306</td>\n",
       "      <td>-0.083894</td>\n",
       "      <td>0.102030</td>\n",
       "      <td>-0.291583</td>\n",
       "      <td>0.145593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.783640</td>\n",
       "      <td>-0.814689</td>\n",
       "      <td>-0.575257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POVRATE15</th>\n",
       "      <td>-0.111678</td>\n",
       "      <td>0.149489</td>\n",
       "      <td>0.430246</td>\n",
       "      <td>0.373430</td>\n",
       "      <td>-0.099466</td>\n",
       "      <td>-0.122713</td>\n",
       "      <td>-0.054436</td>\n",
       "      <td>0.025516</td>\n",
       "      <td>0.189015</td>\n",
       "      <td>-0.196037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087124</td>\n",
       "      <td>-0.156139</td>\n",
       "      <td>0.201709</td>\n",
       "      <td>-0.045336</td>\n",
       "      <td>-0.074526</td>\n",
       "      <td>-0.008683</td>\n",
       "      <td>-0.783640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938094</td>\n",
       "      <td>0.530610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHILDPOVRATE15</th>\n",
       "      <td>-0.115664</td>\n",
       "      <td>0.142085</td>\n",
       "      <td>0.431192</td>\n",
       "      <td>0.368432</td>\n",
       "      <td>-0.111107</td>\n",
       "      <td>-0.088569</td>\n",
       "      <td>-0.023757</td>\n",
       "      <td>0.024937</td>\n",
       "      <td>0.245006</td>\n",
       "      <td>-0.193537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077605</td>\n",
       "      <td>-0.211627</td>\n",
       "      <td>0.157403</td>\n",
       "      <td>-0.053166</td>\n",
       "      <td>0.069784</td>\n",
       "      <td>-0.009211</td>\n",
       "      <td>-0.814689</td>\n",
       "      <td>0.938094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.607158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCT_DIABETES_ADULTS13</th>\n",
       "      <td>-0.184580</td>\n",
       "      <td>-0.032667</td>\n",
       "      <td>0.268348</td>\n",
       "      <td>0.136373</td>\n",
       "      <td>-0.196180</td>\n",
       "      <td>-0.094231</td>\n",
       "      <td>-0.083842</td>\n",
       "      <td>0.025011</td>\n",
       "      <td>0.227950</td>\n",
       "      <td>-0.210047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294174</td>\n",
       "      <td>-0.290610</td>\n",
       "      <td>0.016914</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>0.224886</td>\n",
       "      <td>-0.057354</td>\n",
       "      <td>-0.575257</td>\n",
       "      <td>0.530610</td>\n",
       "      <td>0.607158</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PCT_LACCESS_POP10  PCT_LACCESS_LOWI10  \\\n",
       "PCT_LACCESS_POP10               1.000000            0.901991   \n",
       "PCT_LACCESS_LOWI10              0.901991            1.000000   \n",
       "PCT_LACCESS_HHNV10              0.120353            0.278653   \n",
       "PCT_LACCESS_SNAP15              0.469834            0.625093   \n",
       "PCT_LACCESS_CHILD10             0.960294            0.890419   \n",
       "...                                  ...                 ...   \n",
       "PCT_18YOUNGER10                 0.024031            0.071601   \n",
       "MEDHHINC15                      0.083173           -0.175580   \n",
       "POVRATE15                      -0.111678            0.149489   \n",
       "CHILDPOVRATE15                 -0.115664            0.142085   \n",
       "PCT_DIABETES_ADULTS13          -0.184580           -0.032667   \n",
       "\n",
       "                       PCT_LACCESS_HHNV10  PCT_LACCESS_SNAP15  \\\n",
       "PCT_LACCESS_POP10                0.120353            0.469834   \n",
       "PCT_LACCESS_LOWI10               0.278653            0.625093   \n",
       "PCT_LACCESS_HHNV10               1.000000            0.469096   \n",
       "PCT_LACCESS_SNAP15               0.469096            1.000000   \n",
       "PCT_LACCESS_CHILD10              0.162711            0.514461   \n",
       "...                                   ...                 ...   \n",
       "PCT_18YOUNGER10                  0.083322            0.183683   \n",
       "MEDHHINC15                      -0.348824           -0.287963   \n",
       "POVRATE15                        0.430246            0.373430   \n",
       "CHILDPOVRATE15                   0.431192            0.368432   \n",
       "PCT_DIABETES_ADULTS13            0.268348            0.136373   \n",
       "\n",
       "                       PCT_LACCESS_CHILD10  PCT_LACCESS_SENIORS10  GROCPTH11  \\\n",
       "PCT_LACCESS_POP10                 0.960294               0.919663   0.336424   \n",
       "PCT_LACCESS_LOWI10                0.890419               0.826792   0.312603   \n",
       "PCT_LACCESS_HHNV10                0.162711               0.043476   0.112428   \n",
       "PCT_LACCESS_SNAP15                0.514461               0.350932   0.127557   \n",
       "PCT_LACCESS_CHILD10               1.000000               0.823572   0.291381   \n",
       "...                                    ...                    ...        ...   \n",
       "PCT_18YOUNGER10                   0.215924              -0.142778  -0.110478   \n",
       "MEDHHINC15                        0.110346              -0.008592  -0.050280   \n",
       "POVRATE15                        -0.099466              -0.122713  -0.054436   \n",
       "CHILDPOVRATE15                   -0.111107              -0.088569  -0.023757   \n",
       "PCT_DIABETES_ADULTS13            -0.196180              -0.094231  -0.083842   \n",
       "\n",
       "                       SUPERCPTH11  CONVSPTH11  SPECSPTH11  ...  PCT_HISP10  \\\n",
       "PCT_LACCESS_POP10        -0.114098    0.141654   -0.045043  ...    0.080380   \n",
       "PCT_LACCESS_LOWI10       -0.099019    0.205566   -0.100324  ...    0.125123   \n",
       "PCT_LACCESS_HHNV10       -0.072707    0.083795   -0.123568  ...   -0.118316   \n",
       "PCT_LACCESS_SNAP15       -0.005639    0.100199   -0.107596  ...    0.136538   \n",
       "PCT_LACCESS_CHILD10      -0.093925    0.107640   -0.056868  ...    0.120058   \n",
       "...                            ...         ...         ...  ...         ...   \n",
       "PCT_18YOUNGER10           0.050706   -0.089650   -0.092104  ...    0.308860   \n",
       "MEDHHINC15               -0.049254   -0.294468    0.190558  ...    0.036969   \n",
       "POVRATE15                 0.025516    0.189015   -0.196037  ...    0.087124   \n",
       "CHILDPOVRATE15            0.024937    0.245006   -0.193537  ...    0.077605   \n",
       "PCT_DIABETES_ADULTS13     0.025011    0.227950   -0.210047  ...   -0.294174   \n",
       "\n",
       "                       PCT_NHASIAN10  PCT_NHNA10  PCT_NHPI10  PCT_65OLDER10  \\\n",
       "PCT_LACCESS_POP10          -0.029079    0.157304   -0.010990       0.170400   \n",
       "PCT_LACCESS_LOWI10         -0.104286    0.263290   -0.018282       0.170309   \n",
       "PCT_LACCESS_HHNV10         -0.119366    0.459477   -0.026078      -0.054357   \n",
       "PCT_LACCESS_SNAP15         -0.085277    0.468196   -0.010444      -0.035277   \n",
       "PCT_LACCESS_CHILD10        -0.018676    0.243110   -0.008160       0.046794   \n",
       "...                              ...         ...         ...            ...   \n",
       "PCT_18YOUNGER10            -0.012262    0.291096   -0.104604      -0.528833   \n",
       "MEDHHINC15                  0.431306   -0.083894    0.102030      -0.291583   \n",
       "POVRATE15                  -0.156139    0.201709   -0.045336      -0.074526   \n",
       "CHILDPOVRATE15             -0.211627    0.157403   -0.053166       0.069784   \n",
       "PCT_DIABETES_ADULTS13      -0.290610    0.016914   -0.043644       0.224886   \n",
       "\n",
       "                       PCT_18YOUNGER10  MEDHHINC15  POVRATE15  CHILDPOVRATE15  \\\n",
       "PCT_LACCESS_POP10             0.024031    0.083173  -0.111678       -0.115664   \n",
       "PCT_LACCESS_LOWI10            0.071601   -0.175580   0.149489        0.142085   \n",
       "PCT_LACCESS_HHNV10            0.083322   -0.348824   0.430246        0.431192   \n",
       "PCT_LACCESS_SNAP15            0.183683   -0.287963   0.373430        0.368432   \n",
       "PCT_LACCESS_CHILD10           0.215924    0.110346  -0.099466       -0.111107   \n",
       "...                                ...         ...        ...             ...   \n",
       "PCT_18YOUNGER10               1.000000    0.145593  -0.008683       -0.009211   \n",
       "MEDHHINC15                    0.145593    1.000000  -0.783640       -0.814689   \n",
       "POVRATE15                    -0.008683   -0.783640   1.000000        0.938094   \n",
       "CHILDPOVRATE15               -0.009211   -0.814689   0.938094        1.000000   \n",
       "PCT_DIABETES_ADULTS13        -0.057354   -0.575257   0.530610        0.607158   \n",
       "\n",
       "                       PCT_DIABETES_ADULTS13  \n",
       "PCT_LACCESS_POP10                  -0.184580  \n",
       "PCT_LACCESS_LOWI10                 -0.032667  \n",
       "PCT_LACCESS_HHNV10                  0.268348  \n",
       "PCT_LACCESS_SNAP15                  0.136373  \n",
       "PCT_LACCESS_CHILD10                -0.196180  \n",
       "...                                      ...  \n",
       "PCT_18YOUNGER10                    -0.057354  \n",
       "MEDHHINC15                         -0.575257  \n",
       "POVRATE15                           0.530610  \n",
       "CHILDPOVRATE15                      0.607158  \n",
       "PCT_DIABETES_ADULTS13               1.000000  \n",
       "\n",
       "[69 rows x 69 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCT_LACCESS_LOWI10 | PCT_LACCESS_POP10 | 0.9\n",
      "PCT_LACCESS_CHILD10 | PCT_LACCESS_POP10 | 0.96\n",
      "PCT_LACCESS_SENIORS10 | PCT_LACCESS_POP10 | 0.92\n",
      "PC_FSRSALES12 | PC_FSRSALES07 | 0.91\n",
      "VEG_ACRESPTH12 | VEG_ACRESPTH07 | 1.0\n",
      "FRESHVEG_ACRESPTH12 | FRESHVEG_ACRESPTH07 | 0.95\n",
      "ORCHARD_ACRESPTH12 | ORCHARD_ACRESPTH07 | 0.97\n",
      "BERRY_ACRESPTH12 | BERRY_ACRESPTH07 | 0.98\n",
      "CHILDPOVRATE15 | POVRATE15 | 0.94\n"
     ]
    }
   ],
   "source": [
    "# Iterate through corrmatrix to get column pairs with correlation above threshold of 0.9\n",
    "# Display these pairs\n",
    "\n",
    "\n",
    "iters = range(len(corrmatrix.columns) - 1)\n",
    "drop_cols = []\n",
    "\n",
    "for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corrmatrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= 0.9:\n",
    "                # Print the correlated features and the correlation value\n",
    "                print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List column to drop from each pair\n",
    "drops=['PCT_LACCESS_LOWI10','PCT_LACCESS_CHILD10','PCT_LACCESS_SENIORS10','PC_FSRSALES07','VEG_ACRESPTH07','FRESHVEG_ACRESPTH07','ORCHARD_ACRESPTH07','BERRY_ACRESPTH07','CHILDPOVRATE15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns from dataframe\n",
    "fea_data_sub_numeric=fea_data_sub_numeric.drop(columns=drops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCT_LACCESS_POP10</th>\n",
       "      <th>PCT_LACCESS_HHNV10</th>\n",
       "      <th>PCT_LACCESS_SNAP15</th>\n",
       "      <th>GROCPTH11</th>\n",
       "      <th>SUPERCPTH11</th>\n",
       "      <th>CONVSPTH11</th>\n",
       "      <th>SPECSPTH11</th>\n",
       "      <th>SNAPSPTH12</th>\n",
       "      <th>WICSPTH11</th>\n",
       "      <th>FFRPTH11</th>\n",
       "      <th>...</th>\n",
       "      <th>PCT_NHBLACK10</th>\n",
       "      <th>PCT_HISP10</th>\n",
       "      <th>PCT_NHASIAN10</th>\n",
       "      <th>PCT_NHNA10</th>\n",
       "      <th>PCT_NHPI10</th>\n",
       "      <th>PCT_65OLDER10</th>\n",
       "      <th>PCT_18YOUNGER10</th>\n",
       "      <th>MEDHHINC15</th>\n",
       "      <th>POVRATE15</th>\n",
       "      <th>PCT_DIABETES_ADULTS13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.769657</td>\n",
       "      <td>3.284786</td>\n",
       "      <td>4.608749</td>\n",
       "      <td>0.090581</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.561604</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.674004</td>\n",
       "      <td>0.090567</td>\n",
       "      <td>0.615953</td>\n",
       "      <td>...</td>\n",
       "      <td>17.582599</td>\n",
       "      <td>2.400542</td>\n",
       "      <td>0.855766</td>\n",
       "      <td>0.397647</td>\n",
       "      <td>0.040314</td>\n",
       "      <td>11.995382</td>\n",
       "      <td>26.777959</td>\n",
       "      <td>56580.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.318473</td>\n",
       "      <td>2.147827</td>\n",
       "      <td>1.298900</td>\n",
       "      <td>0.144746</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>0.573622</td>\n",
       "      <td>0.107219</td>\n",
       "      <td>0.725055</td>\n",
       "      <td>0.139380</td>\n",
       "      <td>0.648675</td>\n",
       "      <td>...</td>\n",
       "      <td>9.308425</td>\n",
       "      <td>4.384824</td>\n",
       "      <td>0.735193</td>\n",
       "      <td>0.628755</td>\n",
       "      <td>0.043343</td>\n",
       "      <td>16.771185</td>\n",
       "      <td>22.987408</td>\n",
       "      <td>52387.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.840972</td>\n",
       "      <td>4.135869</td>\n",
       "      <td>4.303147</td>\n",
       "      <td>0.219370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804358</td>\n",
       "      <td>0.109685</td>\n",
       "      <td>1.280590</td>\n",
       "      <td>0.255942</td>\n",
       "      <td>0.694673</td>\n",
       "      <td>...</td>\n",
       "      <td>46.691190</td>\n",
       "      <td>5.051535</td>\n",
       "      <td>0.389700</td>\n",
       "      <td>0.218524</td>\n",
       "      <td>0.087409</td>\n",
       "      <td>14.236807</td>\n",
       "      <td>21.906982</td>\n",
       "      <td>31433.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.559753</td>\n",
       "      <td>3.458580</td>\n",
       "      <td>0.676710</td>\n",
       "      <td>0.263794</td>\n",
       "      <td>0.043966</td>\n",
       "      <td>0.835348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.719122</td>\n",
       "      <td>0.263771</td>\n",
       "      <td>0.263794</td>\n",
       "      <td>...</td>\n",
       "      <td>21.924504</td>\n",
       "      <td>1.771765</td>\n",
       "      <td>0.096007</td>\n",
       "      <td>0.279293</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>12.681650</td>\n",
       "      <td>22.696923</td>\n",
       "      <td>40767.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.700840</td>\n",
       "      <td>3.269380</td>\n",
       "      <td>0.812727</td>\n",
       "      <td>0.121608</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.521177</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.657144</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.347451</td>\n",
       "      <td>...</td>\n",
       "      <td>1.263040</td>\n",
       "      <td>8.070200</td>\n",
       "      <td>0.200621</td>\n",
       "      <td>0.497191</td>\n",
       "      <td>0.031402</td>\n",
       "      <td>14.722096</td>\n",
       "      <td>24.608353</td>\n",
       "      <td>50487.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>30.570505</td>\n",
       "      <td>0.877134</td>\n",
       "      <td>2.141828</td>\n",
       "      <td>0.113603</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.636176</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.428936</td>\n",
       "      <td>0.090948</td>\n",
       "      <td>0.568014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947359</td>\n",
       "      <td>15.269598</td>\n",
       "      <td>0.739625</td>\n",
       "      <td>0.723645</td>\n",
       "      <td>0.093594</td>\n",
       "      <td>8.316212</td>\n",
       "      <td>27.094462</td>\n",
       "      <td>71867.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>29.174527</td>\n",
       "      <td>1.374848</td>\n",
       "      <td>0.670815</td>\n",
       "      <td>0.232818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605327</td>\n",
       "      <td>0.279382</td>\n",
       "      <td>0.242215</td>\n",
       "      <td>0.140095</td>\n",
       "      <td>1.257217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150277</td>\n",
       "      <td>14.985442</td>\n",
       "      <td>1.070724</td>\n",
       "      <td>0.356908</td>\n",
       "      <td>0.061050</td>\n",
       "      <td>9.852541</td>\n",
       "      <td>19.141542</td>\n",
       "      <td>83290.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>20.220414</td>\n",
       "      <td>0.966219</td>\n",
       "      <td>2.072485</td>\n",
       "      <td>0.143548</td>\n",
       "      <td>0.047849</td>\n",
       "      <td>0.574190</td>\n",
       "      <td>0.095698</td>\n",
       "      <td>0.554895</td>\n",
       "      <td>0.143589</td>\n",
       "      <td>0.909134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227294</td>\n",
       "      <td>8.783976</td>\n",
       "      <td>0.279383</td>\n",
       "      <td>0.582442</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>8.873946</td>\n",
       "      <td>30.168577</td>\n",
       "      <td>62968.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>10.915407</td>\n",
       "      <td>0.396304</td>\n",
       "      <td>1.053980</td>\n",
       "      <td>0.236407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.669502</td>\n",
       "      <td>0.236742</td>\n",
       "      <td>0.827423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257823</td>\n",
       "      <td>13.617719</td>\n",
       "      <td>0.539084</td>\n",
       "      <td>0.597680</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>17.672565</td>\n",
       "      <td>25.454119</td>\n",
       "      <td>56088.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>17.209949</td>\n",
       "      <td>1.483037</td>\n",
       "      <td>0.971078</td>\n",
       "      <td>0.560146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976654</td>\n",
       "      <td>0.420050</td>\n",
       "      <td>0.420109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249723</td>\n",
       "      <td>2.996670</td>\n",
       "      <td>0.277469</td>\n",
       "      <td>1.193119</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>15.940622</td>\n",
       "      <td>21.822974</td>\n",
       "      <td>60986.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3143 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PCT_LACCESS_POP10  PCT_LACCESS_HHNV10  PCT_LACCESS_SNAP15  GROCPTH11  \\\n",
       "0             33.769657            3.284786            4.608749   0.090581   \n",
       "1             19.318473            2.147827            1.298900   0.144746   \n",
       "2             20.840972            4.135869            4.303147   0.219370   \n",
       "3              4.559753            3.458580            0.676710   0.263794   \n",
       "4              2.700840            3.269380            0.812727   0.121608   \n",
       "...                 ...                 ...                 ...        ...   \n",
       "3138          30.570505            0.877134            2.141828   0.113603   \n",
       "3139          29.174527            1.374848            0.670815   0.232818   \n",
       "3140          20.220414            0.966219            2.072485   0.143548   \n",
       "3141          10.915407            0.396304            1.053980   0.236407   \n",
       "3142          17.209949            1.483037            0.971078   0.560146   \n",
       "\n",
       "      SUPERCPTH11  CONVSPTH11  SPECSPTH11  SNAPSPTH12  WICSPTH11  FFRPTH11  \\\n",
       "0        0.018116    0.561604    0.018116    0.674004   0.090567  0.615953   \n",
       "1        0.032166    0.573622    0.107219    0.725055   0.139380  0.648675   \n",
       "2        0.000000    0.804358    0.109685    1.280590   0.255942  0.694673   \n",
       "3        0.043966    0.835348    0.000000    0.719122   0.263771  0.263794   \n",
       "4        0.017373    0.521177    0.017373    0.657144   0.139000  0.347451   \n",
       "...           ...         ...         ...         ...        ...       ...   \n",
       "3138     0.022721    0.636176    0.022721    0.428936   0.090948  0.568014   \n",
       "3139     0.000000    0.605327    0.279382    0.242215   0.140095  1.257217   \n",
       "3140     0.047849    0.574190    0.095698    0.554895   0.143589  0.909134   \n",
       "3141     0.000000    0.472813    0.000000    0.669502   0.236742  0.827423   \n",
       "3142     0.000000    0.420109    0.000000    0.976654   0.420050  0.420109   \n",
       "\n",
       "      ...  PCT_NHBLACK10  PCT_HISP10  PCT_NHASIAN10  PCT_NHNA10  PCT_NHPI10  \\\n",
       "0     ...      17.582599    2.400542       0.855766    0.397647    0.040314   \n",
       "1     ...       9.308425    4.384824       0.735193    0.628755    0.043343   \n",
       "2     ...      46.691190    5.051535       0.389700    0.218524    0.087409   \n",
       "3     ...      21.924504    1.771765       0.096007    0.279293    0.030548   \n",
       "4     ...       1.263040    8.070200       0.200621    0.497191    0.031402   \n",
       "...   ...            ...         ...            ...         ...         ...   \n",
       "3138  ...       0.947359   15.269598       0.739625    0.723645    0.093594   \n",
       "3139  ...       0.150277   14.985442       1.070724    0.356908    0.061050   \n",
       "3140  ...       0.227294    8.783976       0.279383    0.582442    0.161000   \n",
       "3141  ...       0.257823   13.617719       0.539084    0.597680    0.011719   \n",
       "3142  ...       0.249723    2.996670       0.277469    1.193119    0.027747   \n",
       "\n",
       "      PCT_65OLDER10  PCT_18YOUNGER10  MEDHHINC15  POVRATE15  \\\n",
       "0         11.995382        26.777959     56580.0       12.7   \n",
       "1         16.771185        22.987408     52387.0       12.9   \n",
       "2         14.236807        21.906982     31433.0       32.0   \n",
       "3         12.681650        22.696923     40767.0       22.2   \n",
       "4         14.722096        24.608353     50487.0       14.7   \n",
       "...             ...              ...         ...        ...   \n",
       "3138       8.316212        27.094462     71867.0        8.5   \n",
       "3139       9.852541        19.141542     83290.0        6.6   \n",
       "3140       8.873946        30.168577     62968.0        9.8   \n",
       "3141      17.672565        25.454119     56088.0       11.2   \n",
       "3142      15.940622        21.822974     60986.0        9.8   \n",
       "\n",
       "      PCT_DIABETES_ADULTS13  \n",
       "0                      13.0  \n",
       "1                      10.4  \n",
       "2                      18.4  \n",
       "3                      14.8  \n",
       "4                      14.1  \n",
       "...                     ...  \n",
       "3138                    8.1  \n",
       "3139                    4.8  \n",
       "3140                    9.0  \n",
       "3141                   12.0  \n",
       "3142                   10.0  \n",
       "\n",
       "[3143 rows x 60 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display dataframe with only selected columns \n",
    "fea_data_sub_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing all of the classifiers we learned about\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Some of these need scaling first to work well \n",
    "# We will also see how polynomial features can give us nonlinear decision boundaries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# We will just use accuracy score for model comparison\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_data_sub_numeric['log_MEDHHINC15'] = np.log10(fea_data_sub_numeric.MEDHHINC15.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEA_df = fea_data_sub_numeric.drop(columns='MEDHHINC15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "further_drops = ['PC_WIC_REDEMP11',\n",
    "                 'PCH_VEG_ACRESPTH_07_12',\n",
    "                 'FRESHVEG_ACRESPTH12',\n",
    "                 'PCH_FRESHVEG_ACRESPTH_07_12',\n",
    "                 'PCH_ORCHARD_ACRESPTH_07_12',\n",
    "                 'BERRY_ACRESPTH12',\n",
    "                 'PCH_BERRY_ACRESPTH_07_12',\n",
    "                 'GHVEG_SQFTPTH07',\n",
    "                 'GHVEG_SQFTPTH12',\n",
    "                 'PCH_GHVEG_SQFTPTH_07_12'       \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEA_df = FEA_df.drop(columns=further_drops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCT_LACCESS_POP10</th>\n",
       "      <th>PCT_LACCESS_HHNV10</th>\n",
       "      <th>PCT_LACCESS_SNAP15</th>\n",
       "      <th>GROCPTH11</th>\n",
       "      <th>SUPERCPTH11</th>\n",
       "      <th>CONVSPTH11</th>\n",
       "      <th>SPECSPTH11</th>\n",
       "      <th>SNAPSPTH12</th>\n",
       "      <th>WICSPTH11</th>\n",
       "      <th>FFRPTH11</th>\n",
       "      <th>...</th>\n",
       "      <th>PCT_NHBLACK10</th>\n",
       "      <th>PCT_HISP10</th>\n",
       "      <th>PCT_NHASIAN10</th>\n",
       "      <th>PCT_NHNA10</th>\n",
       "      <th>PCT_NHPI10</th>\n",
       "      <th>PCT_65OLDER10</th>\n",
       "      <th>PCT_18YOUNGER10</th>\n",
       "      <th>POVRATE15</th>\n",
       "      <th>PCT_DIABETES_ADULTS13</th>\n",
       "      <th>log_MEDHHINC15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.769657</td>\n",
       "      <td>3.284786</td>\n",
       "      <td>4.608749</td>\n",
       "      <td>0.090581</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.561604</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.674004</td>\n",
       "      <td>0.090567</td>\n",
       "      <td>0.615953</td>\n",
       "      <td>...</td>\n",
       "      <td>17.582599</td>\n",
       "      <td>2.400542</td>\n",
       "      <td>0.855766</td>\n",
       "      <td>0.397647</td>\n",
       "      <td>0.040314</td>\n",
       "      <td>11.995382</td>\n",
       "      <td>26.777959</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.752663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.318473</td>\n",
       "      <td>2.147827</td>\n",
       "      <td>1.298900</td>\n",
       "      <td>0.144746</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>0.573622</td>\n",
       "      <td>0.107219</td>\n",
       "      <td>0.725055</td>\n",
       "      <td>0.139380</td>\n",
       "      <td>0.648675</td>\n",
       "      <td>...</td>\n",
       "      <td>9.308425</td>\n",
       "      <td>4.384824</td>\n",
       "      <td>0.735193</td>\n",
       "      <td>0.628755</td>\n",
       "      <td>0.043343</td>\n",
       "      <td>16.771185</td>\n",
       "      <td>22.987408</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4.719224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.840972</td>\n",
       "      <td>4.135869</td>\n",
       "      <td>4.303147</td>\n",
       "      <td>0.219370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804358</td>\n",
       "      <td>0.109685</td>\n",
       "      <td>1.280590</td>\n",
       "      <td>0.255942</td>\n",
       "      <td>0.694673</td>\n",
       "      <td>...</td>\n",
       "      <td>46.691190</td>\n",
       "      <td>5.051535</td>\n",
       "      <td>0.389700</td>\n",
       "      <td>0.218524</td>\n",
       "      <td>0.087409</td>\n",
       "      <td>14.236807</td>\n",
       "      <td>21.906982</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>4.497386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.559753</td>\n",
       "      <td>3.458580</td>\n",
       "      <td>0.676710</td>\n",
       "      <td>0.263794</td>\n",
       "      <td>0.043966</td>\n",
       "      <td>0.835348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.719122</td>\n",
       "      <td>0.263771</td>\n",
       "      <td>0.263794</td>\n",
       "      <td>...</td>\n",
       "      <td>21.924504</td>\n",
       "      <td>1.771765</td>\n",
       "      <td>0.096007</td>\n",
       "      <td>0.279293</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>12.681650</td>\n",
       "      <td>22.696923</td>\n",
       "      <td>22.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>4.610309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.700840</td>\n",
       "      <td>3.269380</td>\n",
       "      <td>0.812727</td>\n",
       "      <td>0.121608</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.521177</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.657144</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.347451</td>\n",
       "      <td>...</td>\n",
       "      <td>1.263040</td>\n",
       "      <td>8.070200</td>\n",
       "      <td>0.200621</td>\n",
       "      <td>0.497191</td>\n",
       "      <td>0.031402</td>\n",
       "      <td>14.722096</td>\n",
       "      <td>24.608353</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.1</td>\n",
       "      <td>4.703180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>30.570505</td>\n",
       "      <td>0.877134</td>\n",
       "      <td>2.141828</td>\n",
       "      <td>0.113603</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.636176</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.428936</td>\n",
       "      <td>0.090948</td>\n",
       "      <td>0.568014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947359</td>\n",
       "      <td>15.269598</td>\n",
       "      <td>0.739625</td>\n",
       "      <td>0.723645</td>\n",
       "      <td>0.093594</td>\n",
       "      <td>8.316212</td>\n",
       "      <td>27.094462</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.856530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>29.174527</td>\n",
       "      <td>1.374848</td>\n",
       "      <td>0.670815</td>\n",
       "      <td>0.232818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605327</td>\n",
       "      <td>0.279382</td>\n",
       "      <td>0.242215</td>\n",
       "      <td>0.140095</td>\n",
       "      <td>1.257217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150277</td>\n",
       "      <td>14.985442</td>\n",
       "      <td>1.070724</td>\n",
       "      <td>0.356908</td>\n",
       "      <td>0.061050</td>\n",
       "      <td>9.852541</td>\n",
       "      <td>19.141542</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.920593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>20.220414</td>\n",
       "      <td>0.966219</td>\n",
       "      <td>2.072485</td>\n",
       "      <td>0.143548</td>\n",
       "      <td>0.047849</td>\n",
       "      <td>0.574190</td>\n",
       "      <td>0.095698</td>\n",
       "      <td>0.554895</td>\n",
       "      <td>0.143589</td>\n",
       "      <td>0.909134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227294</td>\n",
       "      <td>8.783976</td>\n",
       "      <td>0.279383</td>\n",
       "      <td>0.582442</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>8.873946</td>\n",
       "      <td>30.168577</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.799120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>10.915407</td>\n",
       "      <td>0.396304</td>\n",
       "      <td>1.053980</td>\n",
       "      <td>0.236407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.669502</td>\n",
       "      <td>0.236742</td>\n",
       "      <td>0.827423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257823</td>\n",
       "      <td>13.617719</td>\n",
       "      <td>0.539084</td>\n",
       "      <td>0.597680</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>17.672565</td>\n",
       "      <td>25.454119</td>\n",
       "      <td>11.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.748870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>17.209949</td>\n",
       "      <td>1.483037</td>\n",
       "      <td>0.971078</td>\n",
       "      <td>0.560146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976654</td>\n",
       "      <td>0.420050</td>\n",
       "      <td>0.420109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249723</td>\n",
       "      <td>2.996670</td>\n",
       "      <td>0.277469</td>\n",
       "      <td>1.193119</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>15.940622</td>\n",
       "      <td>21.822974</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.785230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3143 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PCT_LACCESS_POP10  PCT_LACCESS_HHNV10  PCT_LACCESS_SNAP15  GROCPTH11  \\\n",
       "0             33.769657            3.284786            4.608749   0.090581   \n",
       "1             19.318473            2.147827            1.298900   0.144746   \n",
       "2             20.840972            4.135869            4.303147   0.219370   \n",
       "3              4.559753            3.458580            0.676710   0.263794   \n",
       "4              2.700840            3.269380            0.812727   0.121608   \n",
       "...                 ...                 ...                 ...        ...   \n",
       "3138          30.570505            0.877134            2.141828   0.113603   \n",
       "3139          29.174527            1.374848            0.670815   0.232818   \n",
       "3140          20.220414            0.966219            2.072485   0.143548   \n",
       "3141          10.915407            0.396304            1.053980   0.236407   \n",
       "3142          17.209949            1.483037            0.971078   0.560146   \n",
       "\n",
       "      SUPERCPTH11  CONVSPTH11  SPECSPTH11  SNAPSPTH12  WICSPTH11  FFRPTH11  \\\n",
       "0        0.018116    0.561604    0.018116    0.674004   0.090567  0.615953   \n",
       "1        0.032166    0.573622    0.107219    0.725055   0.139380  0.648675   \n",
       "2        0.000000    0.804358    0.109685    1.280590   0.255942  0.694673   \n",
       "3        0.043966    0.835348    0.000000    0.719122   0.263771  0.263794   \n",
       "4        0.017373    0.521177    0.017373    0.657144   0.139000  0.347451   \n",
       "...           ...         ...         ...         ...        ...       ...   \n",
       "3138     0.022721    0.636176    0.022721    0.428936   0.090948  0.568014   \n",
       "3139     0.000000    0.605327    0.279382    0.242215   0.140095  1.257217   \n",
       "3140     0.047849    0.574190    0.095698    0.554895   0.143589  0.909134   \n",
       "3141     0.000000    0.472813    0.000000    0.669502   0.236742  0.827423   \n",
       "3142     0.000000    0.420109    0.000000    0.976654   0.420050  0.420109   \n",
       "\n",
       "      ...  PCT_NHBLACK10  PCT_HISP10  PCT_NHASIAN10  PCT_NHNA10  PCT_NHPI10  \\\n",
       "0     ...      17.582599    2.400542       0.855766    0.397647    0.040314   \n",
       "1     ...       9.308425    4.384824       0.735193    0.628755    0.043343   \n",
       "2     ...      46.691190    5.051535       0.389700    0.218524    0.087409   \n",
       "3     ...      21.924504    1.771765       0.096007    0.279293    0.030548   \n",
       "4     ...       1.263040    8.070200       0.200621    0.497191    0.031402   \n",
       "...   ...            ...         ...            ...         ...         ...   \n",
       "3138  ...       0.947359   15.269598       0.739625    0.723645    0.093594   \n",
       "3139  ...       0.150277   14.985442       1.070724    0.356908    0.061050   \n",
       "3140  ...       0.227294    8.783976       0.279383    0.582442    0.161000   \n",
       "3141  ...       0.257823   13.617719       0.539084    0.597680    0.011719   \n",
       "3142  ...       0.249723    2.996670       0.277469    1.193119    0.027747   \n",
       "\n",
       "      PCT_65OLDER10  PCT_18YOUNGER10  POVRATE15  PCT_DIABETES_ADULTS13  \\\n",
       "0         11.995382        26.777959       12.7                   13.0   \n",
       "1         16.771185        22.987408       12.9                   10.4   \n",
       "2         14.236807        21.906982       32.0                   18.4   \n",
       "3         12.681650        22.696923       22.2                   14.8   \n",
       "4         14.722096        24.608353       14.7                   14.1   \n",
       "...             ...              ...        ...                    ...   \n",
       "3138       8.316212        27.094462        8.5                    8.1   \n",
       "3139       9.852541        19.141542        6.6                    4.8   \n",
       "3140       8.873946        30.168577        9.8                    9.0   \n",
       "3141      17.672565        25.454119       11.2                   12.0   \n",
       "3142      15.940622        21.822974        9.8                   10.0   \n",
       "\n",
       "      log_MEDHHINC15  \n",
       "0           4.752663  \n",
       "1           4.719224  \n",
       "2           4.497386  \n",
       "3           4.610309  \n",
       "4           4.703180  \n",
       "...              ...  \n",
       "3138        4.856530  \n",
       "3139        4.920593  \n",
       "3140        4.799120  \n",
       "3141        4.748870  \n",
       "3142        4.785230  \n",
       "\n",
       "[3143 rows x 50 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1790, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEA_df_clean = FEA_df.dropna()\n",
    "FEA_df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Diabetes Rate')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.violinplot(FEA_df_clean.PCT_DIABETES_ADULTS13)\n",
    "plt.ylabel(\"Diabetes Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3875468243224334"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(FEA_df_clean.PCT_DIABETES_ADULTS13) #2.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.199776536312848"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(FEA_df_clean.PCT_DIABETES_ADULTS13) #11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High >13.59 # Middle 13.59>x>8.81 Low <8.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_health(h):\n",
    "    if h < 8.81:\n",
    "        return 0\n",
    "    elif h >= 8.81 and h <= 13.59:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEA_df_clean.insert(50, \"Health\", FEA_df_clean['PCT_DIABETES_ADULTS13'].apply(categorize_health), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCT_LACCESS_POP10</th>\n",
       "      <th>PCT_LACCESS_HHNV10</th>\n",
       "      <th>PCT_LACCESS_SNAP15</th>\n",
       "      <th>GROCPTH11</th>\n",
       "      <th>SUPERCPTH11</th>\n",
       "      <th>CONVSPTH11</th>\n",
       "      <th>SPECSPTH11</th>\n",
       "      <th>SNAPSPTH12</th>\n",
       "      <th>WICSPTH11</th>\n",
       "      <th>FFRPTH11</th>\n",
       "      <th>...</th>\n",
       "      <th>PCT_HISP10</th>\n",
       "      <th>PCT_NHASIAN10</th>\n",
       "      <th>PCT_NHNA10</th>\n",
       "      <th>PCT_NHPI10</th>\n",
       "      <th>PCT_65OLDER10</th>\n",
       "      <th>PCT_18YOUNGER10</th>\n",
       "      <th>POVRATE15</th>\n",
       "      <th>PCT_DIABETES_ADULTS13</th>\n",
       "      <th>log_MEDHHINC15</th>\n",
       "      <th>Health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.769657</td>\n",
       "      <td>3.284786</td>\n",
       "      <td>4.608749</td>\n",
       "      <td>0.090581</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.561604</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.674004</td>\n",
       "      <td>0.090567</td>\n",
       "      <td>0.615953</td>\n",
       "      <td>...</td>\n",
       "      <td>2.400542</td>\n",
       "      <td>0.855766</td>\n",
       "      <td>0.397647</td>\n",
       "      <td>0.040314</td>\n",
       "      <td>11.995382</td>\n",
       "      <td>26.777959</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.752663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.318473</td>\n",
       "      <td>2.147827</td>\n",
       "      <td>1.298900</td>\n",
       "      <td>0.144746</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>0.573622</td>\n",
       "      <td>0.107219</td>\n",
       "      <td>0.725055</td>\n",
       "      <td>0.139380</td>\n",
       "      <td>0.648675</td>\n",
       "      <td>...</td>\n",
       "      <td>4.384824</td>\n",
       "      <td>0.735193</td>\n",
       "      <td>0.628755</td>\n",
       "      <td>0.043343</td>\n",
       "      <td>16.771185</td>\n",
       "      <td>22.987408</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4.719224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.840972</td>\n",
       "      <td>4.135869</td>\n",
       "      <td>4.303147</td>\n",
       "      <td>0.219370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804358</td>\n",
       "      <td>0.109685</td>\n",
       "      <td>1.280590</td>\n",
       "      <td>0.255942</td>\n",
       "      <td>0.694673</td>\n",
       "      <td>...</td>\n",
       "      <td>5.051535</td>\n",
       "      <td>0.389700</td>\n",
       "      <td>0.218524</td>\n",
       "      <td>0.087409</td>\n",
       "      <td>14.236807</td>\n",
       "      <td>21.906982</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>4.497386</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.700840</td>\n",
       "      <td>3.269380</td>\n",
       "      <td>0.812727</td>\n",
       "      <td>0.121608</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.521177</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.657144</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.347451</td>\n",
       "      <td>...</td>\n",
       "      <td>8.070200</td>\n",
       "      <td>0.200621</td>\n",
       "      <td>0.497191</td>\n",
       "      <td>0.031402</td>\n",
       "      <td>14.722096</td>\n",
       "      <td>24.608353</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.1</td>\n",
       "      <td>4.703180</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37.474652</td>\n",
       "      <td>7.285561</td>\n",
       "      <td>6.016623</td>\n",
       "      <td>0.187354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187354</td>\n",
       "      <td>0.093677</td>\n",
       "      <td>1.368468</td>\n",
       "      <td>0.187319</td>\n",
       "      <td>0.374707</td>\n",
       "      <td>...</td>\n",
       "      <td>7.119296</td>\n",
       "      <td>0.183251</td>\n",
       "      <td>0.183251</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>13.459776</td>\n",
       "      <td>22.264981</td>\n",
       "      <td>39.6</td>\n",
       "      <td>19.6</td>\n",
       "      <td>4.451034</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>54.111135</td>\n",
       "      <td>1.692551</td>\n",
       "      <td>4.592067</td>\n",
       "      <td>0.252398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946492</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.606409</td>\n",
       "      <td>0.126318</td>\n",
       "      <td>0.315497</td>\n",
       "      <td>...</td>\n",
       "      <td>16.795719</td>\n",
       "      <td>0.648410</td>\n",
       "      <td>0.761725</td>\n",
       "      <td>0.081838</td>\n",
       "      <td>12.867485</td>\n",
       "      <td>23.613472</td>\n",
       "      <td>11.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4.779661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>15.366399</td>\n",
       "      <td>1.455699</td>\n",
       "      <td>1.157798</td>\n",
       "      <td>0.197433</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>0.592300</td>\n",
       "      <td>0.098717</td>\n",
       "      <td>0.593935</td>\n",
       "      <td>0.222162</td>\n",
       "      <td>0.493583</td>\n",
       "      <td>...</td>\n",
       "      <td>5.642649</td>\n",
       "      <td>0.376343</td>\n",
       "      <td>20.000997</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>14.468011</td>\n",
       "      <td>25.451736</td>\n",
       "      <td>12.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.719398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>13.648370</td>\n",
       "      <td>1.397615</td>\n",
       "      <td>0.428007</td>\n",
       "      <td>0.388695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610806</td>\n",
       "      <td>0.055528</td>\n",
       "      <td>0.695952</td>\n",
       "      <td>0.277639</td>\n",
       "      <td>0.666334</td>\n",
       "      <td>...</td>\n",
       "      <td>4.313487</td>\n",
       "      <td>0.303767</td>\n",
       "      <td>0.695902</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>12.377113</td>\n",
       "      <td>28.189550</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.6</td>\n",
       "      <td>4.794934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>21.079489</td>\n",
       "      <td>0.629671</td>\n",
       "      <td>0.732993</td>\n",
       "      <td>0.105094</td>\n",
       "      <td>0.035031</td>\n",
       "      <td>0.770686</td>\n",
       "      <td>0.105094</td>\n",
       "      <td>0.508095</td>\n",
       "      <td>0.140617</td>\n",
       "      <td>0.735655</td>\n",
       "      <td>...</td>\n",
       "      <td>4.839567</td>\n",
       "      <td>0.581457</td>\n",
       "      <td>0.492820</td>\n",
       "      <td>0.088637</td>\n",
       "      <td>17.521716</td>\n",
       "      <td>20.957277</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.744504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>30.570505</td>\n",
       "      <td>0.877134</td>\n",
       "      <td>2.141828</td>\n",
       "      <td>0.113603</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.636176</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.428936</td>\n",
       "      <td>0.090948</td>\n",
       "      <td>0.568014</td>\n",
       "      <td>...</td>\n",
       "      <td>15.269598</td>\n",
       "      <td>0.739625</td>\n",
       "      <td>0.723645</td>\n",
       "      <td>0.093594</td>\n",
       "      <td>8.316212</td>\n",
       "      <td>27.094462</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.856530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1790 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PCT_LACCESS_POP10  PCT_LACCESS_HHNV10  PCT_LACCESS_SNAP15  GROCPTH11  \\\n",
       "0             33.769657            3.284786            4.608749   0.090581   \n",
       "1             19.318473            2.147827            1.298900   0.144746   \n",
       "2             20.840972            4.135869            4.303147   0.219370   \n",
       "4              2.700840            3.269380            0.812727   0.121608   \n",
       "5             37.474652            7.285561            6.016623   0.187354   \n",
       "...                 ...                 ...                 ...        ...   \n",
       "3123          54.111135            1.692551            4.592067   0.252398   \n",
       "3126          15.366399            1.455699            1.157798   0.197433   \n",
       "3131          13.648370            1.397615            0.428007   0.388695   \n",
       "3134          21.079489            0.629671            0.732993   0.105094   \n",
       "3138          30.570505            0.877134            2.141828   0.113603   \n",
       "\n",
       "      SUPERCPTH11  CONVSPTH11  SPECSPTH11  SNAPSPTH12  WICSPTH11  FFRPTH11  \\\n",
       "0        0.018116    0.561604    0.018116    0.674004   0.090567  0.615953   \n",
       "1        0.032166    0.573622    0.107219    0.725055   0.139380  0.648675   \n",
       "2        0.000000    0.804358    0.109685    1.280590   0.255942  0.694673   \n",
       "4        0.017373    0.521177    0.017373    0.657144   0.139000  0.347451   \n",
       "5        0.000000    0.187354    0.093677    1.368468   0.187319  0.374707   \n",
       "...           ...         ...         ...         ...        ...       ...   \n",
       "3123     0.000000    0.946492    0.063099    0.606409   0.126318  0.315497   \n",
       "3126     0.024679    0.592300    0.098717    0.593935   0.222162  0.493583   \n",
       "3131     0.000000    0.610806    0.055528    0.695952   0.277639  0.666334   \n",
       "3134     0.035031    0.770686    0.105094    0.508095   0.140617  0.735655   \n",
       "3138     0.022721    0.636176    0.022721    0.428936   0.090948  0.568014   \n",
       "\n",
       "      ...  PCT_HISP10  PCT_NHASIAN10  PCT_NHNA10  PCT_NHPI10  PCT_65OLDER10  \\\n",
       "0     ...    2.400542       0.855766    0.397647    0.040314      11.995382   \n",
       "1     ...    4.384824       0.735193    0.628755    0.043343      16.771185   \n",
       "2     ...    5.051535       0.389700    0.218524    0.087409      14.236807   \n",
       "4     ...    8.070200       0.200621    0.497191    0.031402      14.722096   \n",
       "5     ...    7.119296       0.183251    0.183251    0.036650      13.459776   \n",
       "...   ...         ...            ...         ...         ...            ...   \n",
       "3123  ...   16.795719       0.648410    0.761725    0.081838      12.867485   \n",
       "3126  ...    5.642649       0.376343   20.000997    0.017446      14.468011   \n",
       "3131  ...    4.313487       0.303767    0.695902    0.022092      12.377113   \n",
       "3134  ...    4.839567       0.581457    0.492820    0.088637      17.521716   \n",
       "3138  ...   15.269598       0.739625    0.723645    0.093594       8.316212   \n",
       "\n",
       "      PCT_18YOUNGER10  POVRATE15  PCT_DIABETES_ADULTS13  log_MEDHHINC15  \\\n",
       "0           26.777959       12.7                   13.0        4.752663   \n",
       "1           22.987408       12.9                   10.4        4.719224   \n",
       "2           21.906982       32.0                   18.4        4.497386   \n",
       "4           24.608353       14.7                   14.1        4.703180   \n",
       "5           22.264981       39.6                   19.6        4.451034   \n",
       "...               ...        ...                    ...             ...   \n",
       "3123        23.613472       11.4                    8.2        4.779661   \n",
       "3126        25.451736       12.9                    9.6        4.719398   \n",
       "3131        28.189550        8.8                    8.6        4.794934   \n",
       "3134        20.957277        9.6                    8.0        4.744504   \n",
       "3138        27.094462        8.5                    8.1        4.856530   \n",
       "\n",
       "      Health  \n",
       "0          1  \n",
       "1          1  \n",
       "2          2  \n",
       "4          2  \n",
       "5          2  \n",
       "...      ...  \n",
       "3123       0  \n",
       "3126       1  \n",
       "3131       0  \n",
       "3134       0  \n",
       "3138       0  \n",
       "\n",
       "[1790 rows x 51 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEA_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEA_df_clean=FEA_df_clean.drop(columns=\"PCT_DIABETES_ADULTS13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1790, 50)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEA_df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEA_df_clean_train, FEA_df_clean_test = train_test_split(FEA_df_clean.copy(), shuffle=True, random_state=215,\n",
    "                                                         test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEA_df_clean_tt, FEA_df_clean_val = train_test_split(FEA_df_clean_train.copy(), shuffle=True, random_state=215,\n",
    "                                                         test_size =0.2)\n",
    "\n",
    "feature_s_ = FEA_df_clean_tt.columns[:-1]\n",
    "\n",
    "target_s = ['Health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PCT_LACCESS_POP10', 'PCT_LACCESS_HHNV10', 'PCT_LACCESS_SNAP15',\n",
       "       'GROCPTH11', 'SUPERCPTH11', 'CONVSPTH11', 'SPECSPTH11', 'SNAPSPTH12',\n",
       "       'WICSPTH11', 'FFRPTH11', 'FSRPTH11', 'PC_FFRSALES07', 'PC_FFRSALES12',\n",
       "       'PC_FSRSALES12', 'REDEMP_SNAPS12', 'PCT_SNAP12', 'PC_SNAPBEN12',\n",
       "       'SNAP_PART_RATE11', 'PCT_NSLP12', 'PCT_FREE_LUNCH10',\n",
       "       'PCT_REDUCED_LUNCH10', 'PCT_SBP12', 'PCT_SFSP12', 'REDEMP_WICS11',\n",
       "       'PCT_WIC12', 'PCT_CACFP12', 'FOODINSEC_12_14', 'VLFOODSEC_12_14',\n",
       "       'PCT_LOCLFARM07', 'PCT_LOCLFARM12', 'PCT_LOCLSALE07', 'PCT_LOCLSALE12',\n",
       "       'PC_DIRSALES07', 'PC_DIRSALES12', 'PCH_PC_DIRSALES_07_12', 'FMRKTPTH13',\n",
       "       'VEG_ACRESPTH12', 'ORCHARD_ACRESPTH12', 'RECFACPTH11', 'PCT_NHWHITE10',\n",
       "       'PCT_NHBLACK10', 'PCT_HISP10', 'PCT_NHASIAN10', 'PCT_NHNA10',\n",
       "       'PCT_NHPI10', 'PCT_65OLDER10', 'PCT_18YOUNGER10', 'POVRATE15',\n",
       "       'log_MEDHHINC15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_s_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    # Putting linear decision boundary classifiers first\n",
    "    'lda' : LinearDiscriminantAnalysis(),\n",
    "    'log_reg' : LogisticRegression(penalty=None, max_iter= 100000),\n",
    "     'svc_linear' : LinearSVC(dual = 'auto'),\n",
    "\n",
    "    # Quadratic boundaries\n",
    "    'qda' : QuadraticDiscriminantAnalysis(),\n",
    "    'lda_poly' : Pipeline([('scale', StandardScaler()),('poly',PolynomialFeatures(2)),('lda', LinearDiscriminantAnalysis())]),\n",
    "    'log_reg_poly' : Pipeline([('scale', StandardScaler()),('poly',PolynomialFeatures(2)),('log_reg', LogisticRegression(penalty=None, max_iter= 100000))]),\n",
    "    'gnb' : GaussianNB(),\n",
    "\n",
    "    # Complex boundaries\n",
    "    'knn' : Pipeline([('scale', StandardScaler()),('knn', KNeighborsClassifier())]),   \n",
    "    'svc_rbf' : Pipeline([('scale', StandardScaler()),('svc',SVC(kernel= 'rbf'))])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lda': 0.794425087108014,\n",
       " 'log_reg': 0.7735191637630662,\n",
       " 'svc_linear': 0.7003484320557491,\n",
       " 'qda': 0.7003484320557491,\n",
       " 'lda_poly': 0.47038327526132406,\n",
       " 'log_reg_poly': 0.7421602787456446,\n",
       " 'gnb': 0.5574912891986062,\n",
       " 'knn': 0.7804878048780488,\n",
       " 'svc_rbf': 0.794425087108014}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, model in classifiers.items():\n",
    "    model.fit(FEA_df_clean_tt[feature_s_], FEA_df_clean_tt[target_s])\n",
    "\n",
    "accs = {model_name: accuracy_score(FEA_df_clean_val[target_s], model.predict(FEA_df_clean_val[feature_s_])) for model_name, model in classifiers.items()}\n",
    "\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lda': 0.7831654954237002,\n",
       " 'log_reg': 0.8001344215847258,\n",
       " 'svc_linear': 0.8002136752136751,\n",
       " 'qda': 0.6661856661856662,\n",
       " 'lda_poly': 0.4577906370359201,\n",
       " 'log_reg_poly': 0.6839263966923541,\n",
       " 'gnb': 0.5406681190994916,\n",
       " 'knn': 0.7455369192211297,\n",
       " 'svc_rbf': 0.8011763279165655}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, model in classifiers.items():\n",
    "    model.fit(FEA_df_clean_tt[feature_s_], FEA_df_clean_tt[target_s])\n",
    "\n",
    "precs = {model_name: precision_score(FEA_df_clean_val[target_s], model.predict(FEA_df_clean_val[feature_s_]), average='macro') for model_name, model in classifiers.items()}\n",
    "\n",
    "precs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lda': 0.7984237885971868,\n",
       " 'log_reg': 0.78973830911675,\n",
       " 'svc_linear': 0.7458679531850264,\n",
       " 'qda': 0.7471479353012455,\n",
       " 'lda_poly': 0.6132362148403172,\n",
       " 'log_reg_poly': 0.74518128554751,\n",
       " 'gnb': 0.6475731213894772,\n",
       " 'knn': 0.7785634684406003,\n",
       " 'svc_rbf': 0.7989260551626339}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, model in classifiers.items():\n",
    "    model.fit(FEA_df_clean_tt[feature_s_], FEA_df_clean_tt[target_s])\n",
    "\n",
    "precs = {model_name: precision_score(FEA_df_clean_val[target_s], model.predict(FEA_df_clean_val[feature_s_]), average='weighted') for model_name, model in classifiers.items()}\n",
    "\n",
    "precs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lda': 0.6882833571315247,\n",
       " 'log_reg': 0.6148384774039225,\n",
       " 'svc_linear': 0.4149245170187579,\n",
       " 'qda': 0.6948095534482969,\n",
       " 'lda_poly': 0.528310694541061,\n",
       " 'log_reg_poly': 0.6539468385018123,\n",
       " 'gnb': 0.6209192203956602,\n",
       " 'knn': 0.6743095473461965,\n",
       " 'svc_rbf': 0.6439729554912802}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, model in classifiers.items():\n",
    "    model.fit(FEA_df_clean_tt[feature_s_], FEA_df_clean_tt[target_s])\n",
    "\n",
    "recs = {model_name: recall_score(FEA_df_clean_val[target_s], model.predict(FEA_df_clean_val[feature_s_]), average='macro') for model_name, model in classifiers.items()}\n",
    "\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\squis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lda': 0.794425087108014,\n",
       " 'log_reg': 0.7735191637630662,\n",
       " 'svc_linear': 0.7003484320557491,\n",
       " 'qda': 0.7003484320557491,\n",
       " 'lda_poly': 0.47038327526132406,\n",
       " 'log_reg_poly': 0.7421602787456446,\n",
       " 'gnb': 0.5574912891986062,\n",
       " 'knn': 0.7804878048780488,\n",
       " 'svc_rbf': 0.794425087108014}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, model in classifiers.items():\n",
    "    model.fit(FEA_df_clean_tt[feature_s_], FEA_df_clean_tt[target_s])\n",
    "\n",
    "recs = {model_name: recall_score(FEA_df_clean_val[target_s], model.predict(FEA_df_clean_val[feature_s_]), average='weighted') for model_name, model in classifiers.items()}\n",
    "\n",
    "recs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
